---
# PostgreSQL for Airflow metadata (EMBEDDED - Only deployed if standalone postgres not in ENABLED_SERVICES)
# If you have postgres in ENABLED_SERVICES, this section will be skipped and Airflow will use standalone postgres
# To use standalone postgres:
#   1. Add 'postgres' to ENABLED_SERVICES
#   2. Deploy postgres first: ./k8s/scripts/postgres.sh deploy
#   3. Create airflow database: ./k8s/scripts/postgres.sh create-db airflow
#   4. Create airflow user: ./k8s/scripts/postgres.sh create-user airflow airflow
#   5. Grant privileges: ./k8s/scripts/postgres.sh grant airflow airflow
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: airflow-postgres-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: standard

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-postgres
  labels:
    app: airflow-postgres
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-postgres
  template:
    metadata:
      labels:
        app: airflow-postgres
    spec:
      containers:
      - name: postgres
        image: postgres:16-alpine
        env:
        - name: POSTGRES_USER
          value: "airflow"
        - name: POSTGRES_PASSWORD
          value: "airflow"
        - name: POSTGRES_DB
          value: "airflow"
        - name: PGDATA
          value: "/var/lib/postgresql/data/pgdata"
        ports:
        - containerPort: 5432
          name: postgres
        volumeMounts:
        - name: data
          mountPath: /var/lib/postgresql/data
        resources:
          requests:
            memory: "512Mi"
            cpu: "100m"
          limits:
            memory: "1Gi"
            cpu: "500m"
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: airflow-postgres-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: airflow-postgres
  labels:
    app: airflow-postgres
spec:
  ports:
  - port: 5432
    targetPort: 5432
    name: postgres
  selector:
    app: airflow-postgres

---
# ServiceAccount for Airflow
apiVersion: v1
kind: ServiceAccount
metadata:
  name: airflow
  labels:
    app: airflow

---
# Role for Airflow to manage Spark pods
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: airflow-pod-manager
  labels:
    app: airflow
rules:
- apiGroups: [""]
  resources: ["pods", "pods/log", "pods/exec"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]

---
# RoleBinding for Airflow ServiceAccount
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: airflow-pod-manager-binding
  labels:
    app: airflow
subjects:
- kind: ServiceAccount
  name: airflow
roleRef:
  kind: Role
  name: airflow-pod-manager
  apiGroup: rbac.authorization.k8s.io

---
# ConfigMap for DAGs (placeholder - populate via kubectl create configmap)
# To add DAGs: kubectl create configmap airflow-dags --from-file=path/to/dags -n <namespace> --dry-run=client -o yaml | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: airflow-dags
  labels:
    app: airflow
data: {}

---
# Airflow Webserver
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-webserver
  labels:
    app: airflow
    component: webserver
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow
      component: webserver
  template:
    metadata:
      labels:
        app: airflow
        component: webserver
    spec:
      serviceAccountName: airflow
      initContainers:
      - name: copy-dags
        image: busybox:latest
        command:
        - sh
        - -c
        - |
          cp /configmap-dags/* /opt/airflow/dags/ 2>/dev/null || true
        volumeMounts:
        - name: configmap-dags
          mountPath: /configmap-dags
        - name: dags
          mountPath: /opt/airflow/dags
      - name: init-db
        image: apache/airflow:2.7.0-python3.9
        command:
        - bash
        - -c
        - |
          airflow db init
          airflow users create \
            --username admin \
            --password admin \
            --firstname Admin \
            --lastname User \
            --role Admin \
            --email admin@example.com || true
        env:
        - name: POSTGRES_HOST
          value: "airflow-postgres"  # Change to "postgres" if using standalone postgres service
        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
          value: "postgresql+psycopg2://airflow:airflow@$(POSTGRES_HOST):5432/airflow"
        - name: AIRFLOW__CORE__EXECUTOR
          value: "LocalExecutor"
        - name: AIRFLOW__CORE__LOAD_EXAMPLES
          value: "False"
      containers:
      - name: webserver
        image: apache/airflow:2.7.0-python3.9
        command:
        - airflow
        - webserver
        env:
        - name: POSTGRES_HOST
          value: "airflow-postgres"  # Change to "postgres" if using standalone postgres service
        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
          value: "postgresql+psycopg2://airflow:airflow@$(POSTGRES_HOST):5432/airflow"
        - name: AIRFLOW__CORE__EXECUTOR
          value: "LocalExecutor"
        - name: AIRFLOW__WEBSERVER__EXPOSE_CONFIG
          value: "True"
        - name: AIRFLOW__CORE__LOAD_EXAMPLES
          value: "False"
        ports:
        - containerPort: 8080
          name: http
        volumeMounts:
        - name: dags
          mountPath: /opt/airflow/dags
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: configmap-dags
        configMap:
          name: airflow-dags
      - name: dags
        emptyDir: {}

---
# Airflow Scheduler
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-scheduler
  labels:
    app: airflow
    component: scheduler
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow
      component: scheduler
  template:
    metadata:
      labels:
        app: airflow
        component: scheduler
    spec:
      serviceAccountName: airflow
      initContainers:
      - name: copy-dags
        image: busybox:latest
        command:
        - sh
        - -c
        - |
          cp /configmap-dags/* /opt/airflow/dags/ 2>/dev/null || true
        volumeMounts:
        - name: configmap-dags
          mountPath: /configmap-dags
        - name: dags
          mountPath: /opt/airflow/dags
      containers:
      - name: scheduler
        image: apache/airflow:2.7.0-python3.9
        command:
        - airflow
        - scheduler
        env:
        - name: POSTGRES_HOST
          value: "airflow-postgres"  # Change to "postgres" if using standalone postgres service
        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
          value: "postgresql+psycopg2://airflow:airflow@$(POSTGRES_HOST):5432/airflow"
        - name: AIRFLOW__CORE__EXECUTOR
          value: "LocalExecutor"
        - name: AIRFLOW__CORE__LOAD_EXAMPLES
          value: "False"
        volumeMounts:
        - name: dags
          mountPath: /opt/airflow/dags
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
      volumes:
      - name: configmap-dags
        configMap:
          name: airflow-dags
      - name: dags
        emptyDir: {}

---
# Airflow Webserver Service
apiVersion: v1
kind: Service
metadata:
  name: airflow-webserver
  labels:
    app: airflow
    component: webserver
spec:
  type: NodePort
  ports:
  - port: 8080
    targetPort: 8080
    name: http
  selector:
    app: airflow
    component: webserver
