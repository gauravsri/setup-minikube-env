---
# Spark Master Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-master
  labels:
    app: spark
    component: master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark
      component: master
  template:
    metadata:
      labels:
        app: spark
        component: master
    spec:
      enableServiceLinks: false
      containers:
      - name: spark-master
        image: apache/spark:3.5.3
        command: ["/opt/spark/bin/spark-class"]
        args: ["org.apache.spark.deploy.master.Master", "--host", "0.0.0.0", "--port", "7077", "--webui-port", "8080"]
        env:
        - name: SPARK_NO_DAEMONIZE
          value: "true"
        - name: SPARK_MASTER_OPTS
          value: "-Dspark.eventLog.enabled=true -Dspark.eventLog.dir=s3a://spark-events/ -Dspark.hadoop.fs.s3a.endpoint=http://minio:9000 -Dspark.hadoop.fs.s3a.access.key=minioadmin -Dspark.hadoop.fs.s3a.secret.key=minioadmin -Dspark.hadoop.fs.s3a.path.style.access=true -Dspark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem -Dspark.hadoop.fs.s3a.connection.ssl.enabled=false"
        ports:
        - containerPort: 8080
          name: web
        - containerPort: 7077
          name: master
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /
            port: 8080
          initialDelaySeconds: 20
          periodSeconds: 10

---
# Spark Master Service
apiVersion: v1
kind: Service
metadata:
  name: spark-master
  labels:
    app: spark
    component: master
spec:
  type: NodePort
  ports:
  - port: 8080
    targetPort: 8080
    name: web
  - port: 7077
    targetPort: 7077
    name: master
  selector:
    app: spark
    component: master

---
# Spark Worker Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-worker
  labels:
    app: spark
    component: worker
spec:
  replicas: 2
  selector:
    matchLabels:
      app: spark
      component: worker
  template:
    metadata:
      labels:
        app: spark
        component: worker
    spec:
      enableServiceLinks: false
      containers:
      - name: spark-worker
        image: apache/spark:3.5.3
        command: ["/opt/spark/bin/spark-class"]
        args: ["org.apache.spark.deploy.worker.Worker", "--webui-port", "8081", "--memory", "1G", "--cores", "1", "spark://spark-master:7077"]
        env:
        - name: SPARK_NO_DAEMONIZE
          value: "true"
        ports:
        - containerPort: 8081
          name: web
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /
            port: 8081
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /
            port: 8081
          initialDelaySeconds: 20
          periodSeconds: 10

---
# Spark Worker Service
apiVersion: v1
kind: Service
metadata:
  name: spark-worker
  labels:
    app: spark
    component: worker
spec:
  type: NodePort
  ports:
  - port: 8081
    targetPort: 8081
    name: web
  selector:
    app: spark
    component: worker

---
# Spark History Server Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-history
  labels:
    app: spark
    component: history
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark
      component: history
  template:
    metadata:
      labels:
        app: spark
        component: history
    spec:
      enableServiceLinks: false
      initContainers:
      - name: download-aws-jars
        image: curlimages/curl:latest
        command: ["/bin/sh", "-c"]
        args:
        - |
          mkdir -p /opt/spark/jars
          cd /opt/spark/jars
          curl -O https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar
          curl -O https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar
        volumeMounts:
        - name: spark-jars
          mountPath: /opt/spark/jars
      containers:
      - name: spark-history
        image: apache/spark:3.5.3
        command: ["/opt/spark/bin/spark-class"]
        args: ["org.apache.spark.deploy.history.HistoryServer"]
        env:
        - name: SPARK_NO_DAEMONIZE
          value: "true"
        - name: SPARK_DIST_CLASSPATH
          value: "/opt/spark/jars-extra/*"
        - name: SPARK_HISTORY_OPTS
          value: "-Dspark.history.fs.logDirectory=s3a://spark-events/ -Dspark.hadoop.fs.s3a.endpoint=http://minio:9000 -Dspark.hadoop.fs.s3a.access.key=minioadmin -Dspark.hadoop.fs.s3a.secret.key=minioadmin -Dspark.hadoop.fs.s3a.path.style.access=true -Dspark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem -Dspark.hadoop.fs.s3a.connection.ssl.enabled=false"
        volumeMounts:
        - name: spark-jars
          mountPath: /opt/spark/jars-extra
        ports:
        - containerPort: 18080
          name: web
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /
            port: 18080
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /
            port: 18080
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: spark-jars
        emptyDir: {}

---
# Spark History Server Service
apiVersion: v1
kind: Service
metadata:
  name: spark-history
  labels:
    app: spark
    component: history
spec:
  type: NodePort
  ports:
  - port: 18080
    targetPort: 18080
    name: web
  selector:
    app: spark
    component: history
